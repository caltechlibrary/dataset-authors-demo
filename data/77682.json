{"title":"Learning-Based Abstractions for Nonlinear Constraint Solving","uri":"","abstract":"We propose a new abstraction refinement procedure based on machine learning to improve the performance of nonlinear constraint solving algorithms on large-scale problems. The proposed approach decomposes the original set of constraints into smaller subsets, and uses learning algorithms to propose sequences of abstractions that take the form of conjunctions of classifiers. The core procedure is a refinement loop that keeps improving the learned results based on counterexamples that are obtained from partial constraints that are easy to solve. Experiments show that the proposed techniques significantly improved the performance of state-of-the-art constraint solvers on many challenging benchmarks. The mechanism is capable of producing intermediate symbolic abstractions that are also important for many applications and for understanding the internal structures of hard constraint solving problems.","documents":[{"id":"http://authors.library.caltech.edu/id/document/252637","docid":252637,"rev_number":2,"files":[{"id":"http://authors.library.caltech.edu/id/file/1262198","fileid":1262198,"datasetid":"document","objectid":252637,"filename":"3f140e46-a9be-4750-afeb-eeddb3a821ff.out.pdf","mime_type":"application/pdf","hash":"b223a09cfa5c45c420bf86aef6db6308","hash_type":"MD5","filesize":293797,"mtime":"2017-05-24 07:29:17","url":"http://authors.library.caltech.edu/77682/1/3f140e46-a9be-4750-afeb-eeddb3a821ff.out.pdf"}],"eprintid":77682,"pos":1,"placement":1,"mime_type":"application/pdf","format":"application/pdf","language":"en","security":"public","license":"other","main":"3f140e46-a9be-4750-afeb-eeddb3a821ff.out.pdf","content":"submitted"}],"note":"This work was partially supported by STARnet, a Semiconductor Research Corporation program, sponsored by MARCO and DARPA and in part by Toyota InfoTechnology Center and NSF CPS1446725. The authors would also like to thank Joel W. Burdick for helpful input.","id":77682,"rev_number":10,"userid":5435,"eprint_dir":"disk0/00/07/76/82","datestamp":"2017-05-24 16:59:30","lastmod":"2017-05-25 19:27:03","status_changed":"2017-05-24 16:59:30","type":"conference_item","metadata_visibility":"show","creators":[{"given":"Sumanth","family":"Dathathri","id":"Dathathri-S","orcid":""},{"given":"Nikos","family":"Aréchiga","id":"Aréchiga-N","orcid":""},{"given":"Sicun","family":"Gao","id":"Gao-Sicun","orcid":""},{"given":"Richard M.","family":"Murray","id":"Murray-R-M","orcid":"0000-0002-5785-7481"}],"ispublished":"inpress","subjects":null,"full_text_status":"public","keywords":"Symbolic Algorithms, Machine Learning, Interpolants, Constraint Solving, Machine Intelligence","date":"2017-08-20","date_type":"published","publication":"","volume":"","number":"","pagerange":"","id_number":"CaltechAUTHORS:20170523-230106516","refereed":true,"issn":"","official_url":"http://resolver.caltech.edu/CaltechAUTHORS:20170523-230106516","related_url":null,"referencetext":["[Albargouthi and McMillan, 2013] Albargouthi, A., and\nMcMillan, K. L. 2013. Beautiful interpolants. In\nComputer Aided Verification.\n[Arechiga et al., 2015 ´ ] Arechiga, N.; Kapinski, J.; Desh- ´\nmukh, J. V.; Platzer, A.; and Krogh, B. 2015. Forward\ninvariant cuts to simplify proofs of safety. In Embedded\nSoftware.\n[Bacchus, Dalmao, and Pitassi, 2009] Bacchus, F.; Dalmao,\nS.; and Pitassi, T. 2009. Solving #sat and bayesian\ninference with backtracking search. J. Artif. Int. Res.\n34(1):391–442.\n[Boser, Guyon, and Vapnik, 1992] Boser, B. E.; Guyon,\nI. M.; and Vapnik, V. N. 1992. A training algorithm for\noptimal margin classifiers. In Proceedings of the Fifth Annual\nWorkshop on Computational Learning Theory, COLT\n’92, 144–152. New York, NY, USA: ACM.\n[Brown and Davenport, 2007] Brown, C. W., and Davenport,\nJ. H. 2007. The complexity of quantifier elimination and\ncylindrical algebraic decomposition. In Proceedings of the\n2007 International Symposium on Symbolic and Algebraic\nComputation.\n[Clarke et al., 2000] Clarke, E.; Grumberg, O.; Jha, S.; Lu,\nY.; and Veith, H. 2000. Counterexample-guided abstraction\nrefinement. In Computer Aided Verification: 12th International\nConference.\n[Cortes and Vapnik, 1995] Cortes, C., and Vapnik, V. 1995.\nSupport-vector networks. Machine Learning 20(3):273–\n297.\n[Darwiche, 2001] Darwiche, A. 2001. Recursive conditioning.\nArtif. Intell. 126(1-2):5–41.\n[Drews and Albarghouthi, 2016] Drews, S., and Albarghouthi,\nA. 2016. Effectively propositional interpolants. In\nComputer Aided Verification.\n[Friesen and Domingos, 2015] Friesen, A. L., and Domingos,\nP. 2015. Recursive decomposition for nonconvex\noptimization. In Proceedings of the 24th International\nConference on Artificial Intelligence, IJCAI’15, 253–259.\nAAAI Press.\n[Gao, Kong, and Clarke, 2013] Gao, S.; Kong, S.; and\nClarke, E. M. 2013. dReal: An SMT Solver for Nonlinear\nTheories over the Reals. Berlin, Heidelberg: Springer\nBerlin Heidelberg. 208–214.\n[Gorcitz et al., 2015] Gorcitz, R.; Kofman, E.; Carle, T.;\nPotop-Butucaru, D.; and de Simone, R. 2015. On the\nScalability of Constraint Solving for Static/Off-Line RealTime\nScheduling. Cham: Springer International Publishing.\n108–123.\n[Graf et al., 2004] Graf, H. P.; Cosatto, E.; Bottou, L.; Dourdanovic,\nI.; and Vapnik, V. 2004. Parallel support vector\nmachines: The cascade svm. In Saul, L. K.; Weiss, Y.; and\nBottou, L., eds., Advances in Neural Information Processing\nSystems 17. Cambridge, MA: MIT Press. 521–528.\n[Jovanovic and de Moura, 2013 ´ ] Jovanovic, D., and ´\nde Moura, L. 2013. Solving non-linear arithmetic.\nACM Commun. Comput. Algebra 46(3/4):104–105.\n[Lloyd, 2006] Lloyd, S. 2006. Least squares quantization in\npcm. IEEE Trans. Inf. Theor. 28(2):129–137.\n[Sharma, Nori, and Aiken, 2012] Sharma, R.; Nori, A. V.;\nand Aiken, A. 2012. Interpolants as classifiers. In Computer\nAided Verification.\n[Stanley-Marbell, Francese, and Rinard, 2016] StanleyMarbell,\nP.; Francese, P. A.; and Rinard, M. 2016.\nEncoder logic for reducing serial i/o power in sensors\nand sensor hubs. In 28th Annual IEEE Symposium on\nHigh-Performance Chips (Hot Chips’16).\n[Tarski, 1951] Tarski, A. 1951. A Decision Method for Elementary\nAlgebra and Geometry. Berkeley: University of\nCalifornia Press, 2nd edition.\n[Ting and Zhu, 2009] Ting, K. M., and Zhu, L. 2009. Boosting\nSupport Vector Machines Successfully. Berlin, Heidelberg:\nSpringer Berlin Heidelberg. 509–518.\n[Wu et al., 2008] Wu, S.-H.; Lin, K.-P.; Chen, C.-M.; and\nChen, M.-S. 2008. Asymmetric support vector machines:\nLow false-positive learning under the user tolerance. In\nProceedings of the 14th ACM SIGKDD International Conference\non Knowledge Discovery and Data Mining, KDD\n’08, 749–757. New York, NY, USA: ACM.\n[Wu et al., 2013] Wu, S.-H.; Lin, K.-P.; Chien, H.-H.; Chen,\nC.-M.; and Chen, M.-S. 2013. On generalizable low\nfalse-positive learning using asymmetric support vector\nmachines. IEEE Transactions on Knowledge and Data Engineering\n25(5):1083–1096."],"rights":"No commercial reproduction, distribution, display or performance rights in this work are provided.","official_citation":"","other_numbering_system":null,"funders":[{"agency":"STARnet","grant_number":""},{"agency":"Toyota InfoTechnology Center","grant_number":""},{"agency":"NSF","grant_number":"CPS-1446725"}],"collection":"CaltechAUTHORS","reviewer":"GP","local_group":null}