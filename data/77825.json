{"title":"Causal Feature Learning: An Overview","uri":"","abstract":"Causal feature learning (CFL) (Chalupka et al., Proceedings of the Thirty-First Conference on Uncertainty in Artificial Intelligence. AUAI Press, Edinburgh, pp 181–190, 2015) is a causal inference framework rooted in the language of causal graphical models (Pearl J, Reasoning and inference. Cambridge University Press, Cambridge, 2009; Spirtes et al., Causation, Prediction, and Search. Massachusetts Institute of Technology, Massachusetts, 2000), and computational mechanics (Shalizi, PhD thesis, University of Wisconsin at Madison, 2001). CFL is aimed at discovering high-level causal relations from low-level data, and at reducing the experimental effort to understand confounding among the high-level variables. We first review the scientific motivation for CFL, then present a detailed introduction to the framework, laying out the definitions and algorithmic steps. A simple example illustrates the techniques involved in the learning steps and provides visual intuition. Finally, we discuss the limitations of the current framework and list a number of open problems.","documents":[{"id":"http://authors.library.caltech.edu/id/document/252871","docid":252871,"rev_number":4,"files":[{"id":"http://authors.library.caltech.edu/id/file/1264329","fileid":1264329,"datasetid":"document","objectid":252871,"filename":"art%3A10.1007%2Fs41237-016-0008-2.pdf","mime_type":"application/pdf","hash":"3e0b65ad5e13dd18ed21a0eb0e233945","hash_type":"MD5","filesize":2786040,"mtime":"2017-05-30 16:45:14","url":"http://authors.library.caltech.edu/77825/1/art%253A10.1007%252Fs41237-016-0008-2.pdf"}],"eprintid":77825,"pos":1,"placement":1,"mime_type":"application/pdf","format":"application/pdf","language":"en","security":"internal","license":"other","main":"art%3A10.1007%2Fs41237-016-0008-2.pdf","content":"published"}],"note":"© The Behaviormetric Society 2016. \n\nReceived: 29 August 2016 / Accepted: 29 November 2016 / Published online: 26 December 2016. \n\nCommunicated by Shohei Shimizu. \n\nWe thank an anonymous reviewer for pointing out an error in our original theorem. This work was supported by NSF Award #1564330. \n\nOn behalf of all authors, the corresponding author states that there is no conflict of interest.","id":77825,"rev_number":11,"userid":6,"eprint_dir":"disk0/00/07/78/25","datestamp":"2017-05-30 17:16:55","lastmod":"2017-05-30 17:23:07","status_changed":"2017-05-30 17:16:55","type":"article","metadata_visibility":"show","creators":[{"given":"Krzysztof","family":"Chalupka","id":"Chalupka-K","orcid":"0000-0002-1225-2112"},{"given":"Frederick","family":"Eberhardt","id":"Eberhardt-F","orcid":""},{"given":"Pietro","family":"Perona","id":"Perona-P","orcid":"0000-0002-7583-5809"}],"ispublished":"pub","subjects":null,"full_text_status":"none","keywords":"Causal discovery; Causal inference; Graphical models; Bayesian networks; Macrovariables; Multiscale modeling","date":"2017-01","date_type":"published","publication":"Behaviormetrika","volume":"44","number":"1","pagerange":"137-164","id_number":"CaltechAUTHORS:20170530-090152248","refereed":true,"issn":"0385-7417","official_url":"http://resolver.caltech.edu/CaltechAUTHORS:20170530-090152248","related_url":[{"url":"https://dx.doi.org/10.1007/s41237-016-0008-2","type":"doi","description":"Article"},{"url":"https://link.springer.com/article/10.1007/s41237-016-0008-2","type":"pub","description":"Article"},{"url":"http://rdcu.be/s6Fx","type":"pub","description":"Free ReadCube access"}],"referencetext":["Bishop CM (1994) Mixture density networks. Technical report\nChaloner K, Verdinelli I (1995) Bayesian experimental design: a review. Stat Sci 273–304\nChalupka K, Perona P, Eberhardt F (2015) Visual causal feature learning. In: Proceedings of the thirty-first conference on uncertainty in artificial intelligence. AUAI Press, Corvallis, pp 181–190\nChalupka K, Bischoff T, Perona P, Eberhardt F (2016a) Unsupervised discovery of el nino using causal feature learning on microlevel climate data. In: Proceedings of the thirty-second conference on uncertainty in artificial intelligence\nChalupka K, Perona P, Eberhardt F (2016b) Multi-level cause-effect systems. In: 19th international conference on artificial intelligence and statistics (AISTATS)\nChickering DM (2002) Learning equivalence classes of bayesian-network structures. J Mach Learn Res 2:445–498\nMathSciNetMATHGoogle Scholar\nClaassen T, Heskes T (2012) A bayesian approach to constraint based causal inference. In: Proceedings of UAI. AUAI Press, Corvallis, pp 207–216\nEntner Doris, Hoyer Patrik O (2012) Estimating a causal order among groups of variables in linear models. Artif Neural Netw Mach Learn-ICANN 2012:84–91\nGoogle Scholar\nHoel Erik P, Albantakis L, Tononi G, Albantakis GT (2013) Quantifying causal emergence shows that macro can beat micro. Proc Natl Acad Sci 110(49):19790–19795\nCrossRefGoogle Scholar\nHoyer PO, Janzing D, Mooij JM, Peters J, Schölkopf B (2009) Nonlinear causal discovery with additive noise models. In: Advances in neural information processing systems, pp 689–696\nHyttinen A, Eberhardt F, Hoyer PO (2012) Causal discovery of linear cyclic models from multiple experimental data sets with overlapping variables. arXiv:1210.4879\nHyttinen A, Frederick E, Järvisalo M (2014) Conflict resolution with answer set programming. In: Proceedings of UAI, constraint-based causal discovery\nJacobs KW, Hustmyer FE (1974) Effects of four psychological primary colors on gsr, heart rate and respiration rate. Percept Motor Skills 38(3):763–766\nCrossRefGoogle Scholar\nKrizhevsky A, Sutskever I, Hinton GE (2012) ImageNet classification with deep convolutional neural networks. In: Pereira F, Burges CJC, Bottou L, Weinberger KO (eds). Advances in neural information processing systems, vol 25, pp 1097–1105\nLacerda G, Spirtes PL, Ramsey J, Hoyer PO (2012) Discovering cyclic causal models by independent components analysis. arXiv:1206.3273\nLevina E, Bickel P (2001) The earth mover’s distance is the mallows distance: some insights from statistics. In: Eighth IEEE international conference on computer vision, 2001. ICCV 2001. Proceedings, vol 2. IEEE, New York, pp 251–256\nMooij JM, Janzing D, Heskes T, Schölkopf B (2011) On causal discovery with cyclic additive noise models. In: Advances in neural information processing systems, pp 639–647\nOkamoto M (1973) Distinctness of the eigenvalues of a quadratic form in a multivariate sample. Ann Stat 1(4):763–765\nMathSciNetCrossRefMATHGoogle Scholar\nParviainen P, Kaski S (2015) Bayesian networks for variable groups. arXiv:1508.07753\nPearl J (2000) Causality: models. Reasoning and inference. Cambridge University Press, Cambridge\nMATHGoogle Scholar\nPearl J (2010) An introduction to causal inference. Int J Biostat 6(2)\nReise SP, Moore TM, Haviland MG (2010) Bifactor models and rotations: Exploring the extent to which multidimensional data yield univocal scale scores. J Pers Assessm 92(6):544–559\nCrossRefGoogle Scholar\nRichardson T (1996) A discovery algorithm for directed cyclic graphs. In: Proceedings of the twelfth international conference on uncertainty in artificial intelligence. Morgan Kaufmann Publishers Inc., USA, pp 454–461\nRumelhart DE, Hinton GE, Williams RJ (1985) Learning internal representations by error propagation. Technical report, No. ICS-8506. California University of San Diego La Jolla Institute for Cognitive Science\nShalizi CR (2001) Causal architecture, complexity and self-organization in the time series and cellular automata. PhD thesis, University of Wisconsin at Madison\nShalizi CR, Crutchfield JP (2001) Computational mechanics: pattern and prediction, structure and simplicity. J Stat Phys 104(3–4):817–879\nMathSciNetCrossRefMATHGoogle Scholar\nShalizi CR, Moore C (2003) What is a macrostate? Subjective observations and objective dynamics. arXiv:cond-mat/0303625\nShimizu Shohei, Hoyer Patrik O, Hyvärinen Aapo, Kerminen Antti (2006) A linear non-gaussian acyclic model for causal discovery. J Mach Learn Res 7:2003–2030\nMathSciNetMATHGoogle Scholar\nSilander T, Myllymäki P (2006) A simple approach for finding the globally optimal bayesian network structure. In: Proc UAI. AUAI Press, Oregon, pp 445–452\nSilva R, Scheines R, Glymour C, Spirtes P (2006) Learning the structure of linear latent variable models. J Mach Learn Res 7:191–246\nMathSciNetMATHGoogle Scholar\nSnoek J, Larochelle H, Adams RP (2012) Practical bayesian optimization of machine learning algorithms. In: Advances in neural information processing systems, pp 2951–2959\nSpirtes Peter, Scheines Richard (2004) Causal inference of ambiguous manipulations. Philos Sci 71(5):833–845\nMathSciNetCrossRefGoogle Scholar\nSpirtes P, Glymour CN, Scheines R (2000) Causation, prediction, and search, 2nd edn. Massachusetts Institute of Technology, Massachusetts\nSrinivas N, Krause A, Seeger M, Kakade SM (2010) Gaussian process optimization in the bandit setting: no regret and experimental design. In: Proceedings of the 27th international conference on machine learning (ICML-10), pp 1015–1022\nTong S, Koller D (2001) Support vector machine active learning with applications to text classification. J Mach Learn Res 2:45–66\nMATHGoogle Scholar\nTsao Doris Y, Freiwald Winrich A, Tootell RBH, Livingstone MS (2006) A cortical region consisting entirely of face-selective cells. Science 311(5761):670–674"],"rights":"No commercial reproduction, distribution, display or performance rights in this work are provided.","official_citation":"Chalupka, K., Eberhardt, F. \u0026 Perona, P. Behaviormetrika (2017) 44: 137. doi:10.1007/s41237-016-0008-2","other_numbering_system":null,"funders":[{"agency":"NSF","grant_number":"IIS-1564330"}],"collection":"CaltechAUTHORS","reviewer":"","local_group":null}